{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 'normal': 420 images\n",
      "Min pixel value: 0.0\n",
      "Max pixel value: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Defining Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((500,500)),\n",
    "    transforms.ToTensor()\n",
    "    #transforms.Normalize(mean=[0.5,0.5,0.5], std=[.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "negImg = datasets.ImageFolder(root=\"datasets/sixray/train_data/\",transform=transform)\n",
    "\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(negImg, batch_size=4, shuffle=False)\n",
    "\n",
    "# Get the class-to-index mapping\n",
    "class_to_idx = negImg.class_to_idx\n",
    "\n",
    "# Initialize a dictionary to store the counts\n",
    "class_counts = {class_label: 0 for class_label in class_to_idx.values()}\n",
    "\n",
    "# Iterate over the dataset\n",
    "for _, class_label in negImg:\n",
    "    class_counts[class_label] += 1\n",
    "\n",
    "# Print the counts for each class\n",
    "for class_label, count in class_counts.items():\n",
    "    class_name = negImg.classes[class_label]\n",
    "    print(f\"Class '{class_name}': {count} images\")\n",
    "\n",
    "\n",
    "# Initialize variables to store min and max pixel values\n",
    "min_pixel_value = float('inf')\n",
    "max_pixel_value = float('-inf')\n",
    "\n",
    "# Iterate over the dataset\n",
    "for images, _ in dataloader:\n",
    "    # Calculate the current min and max pixel values\n",
    "    current_min = torch.min(images)\n",
    "    current_max = torch.max(images)\n",
    "\n",
    "    # Update min and max values if necessary\n",
    "    min_pixel_value = min(min_pixel_value, current_min)\n",
    "    max_pixel_value = max(max_pixel_value, current_max)\n",
    "\n",
    "# Print the min and max pixel values\n",
    "print(\"Min pixel value:\", min_pixel_value.item())\n",
    "print(\"Max pixel value:\", max_pixel_value.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images from the data loader\n",
    "images, _ = next(iter(dataloader))\n",
    "\n",
    "# Plot the images\n",
    "fig, axes = plt.subplots(1, len(images), figsize=(10, 5))\n",
    "\n",
    "for idx, image in enumerate(images):\n",
    "    # Convert the image tensor to a NumPy array and transpose the dimensions\n",
    "    image_np = image.numpy().transpose(1, 2, 0)\n",
    "\n",
    "    # Clip the values to the valid range [0, 1]\n",
    "    image_np = np.clip(image_np, 0, 1)\n",
    "    \n",
    "    # Plot the image\n",
    "    axes[idx].imshow(image_np)\n",
    "    axes[idx].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in dataloader:\n",
    "    # Print the min and max pixel values\n",
    "    print(\"Min pixel value:\", torch.min(images).item())\n",
    "    print(\"Max pixel value:\", torch.max(images).item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_CNN(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3,16,3 ,stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "\n",
    "            nn.Conv2d(16,8,3, stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "\n",
    "            nn.Conv2d(8,8,3, stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8,8,3 ,stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "\n",
    "            nn.ConvTranspose2d(8,16,3, stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2,mode='bilinear'),\n",
    "\n",
    "            nn.ConvTranspose2d(16,3,3, stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2,mode='bilinear')\n",
    "\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
